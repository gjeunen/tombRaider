#! /usr/bin/env python3


##################
# IMPORT MODULES #
##################
import argparse
from tqdm import tqdm
import os
import itertools
from Bio import pairwise2
import collections

from function import __version__
from function.tombRaiderFunctions import freqToMemory, zotuToMemory, taxToMemory, dictionarySum


#########################
# MODULE mrcaCalculator #
#########################
# function to calculate the most recent common ancestor from BLAST
def mrcaCalculator(args):
    INPUT = args.input


#####################
# MODULE mrcaMerger #
#####################
# function to merge sequences based on the most recent common ancestor ID
def mrcaMerger(args):
    INPUT = args.input


######################
# MODULE occurMerger #
######################
# function to merge sequences based on co-occurrence patterns
def occurMerger(args):
    INPUT = args.input


#####################
# MODULE tombRaider #
#####################
# function to merge sequences based on taxon-dependent co-occurrence patterns
def tombRaider(args):
    FREQ = args.freq
    ZOTU = args.zotu
    TAX = args.tax
    OUTPUT = args.output

## starting print statement
    print(f'\ntombRaider v{__version__}\nhttps://github.com/gjeunen/tombRaider\n\n')

## read FREQ, ZOTU, and TAX into memory
    try:
       with tqdm(total = os.path.getsize(FREQ) + os.path.getsize(ZOTU) + os.path.getsize(TAX), desc = f'Reading Input Files into memory: ', bar_format = '{desc}{percentage:.1f}%|{bar}|{elapsed}<{remaining}') as pbar:
           freqInputDict, freqTotalCountDict, pbar = freqToMemory(FREQ, pbar)
           seqInputDict, pbar = zotuToMemory(ZOTU, pbar)
           taxIdInputDict, taxQcovInputDict, taxPidentInputDict, pbar = taxToMemory(TAX, pbar)
    except TypeError:
       print(f'FATAL ERROR: "-f", "--freq" and/or "-z", "--zotu" and/or "-t", "--tax" parameter(s) not provided, aborting analysis...\n')
       exit()
    except FileNotFoundError:
       print(f'FATAL ERROR: {FREQ} and/or {ZOTU} and/or {TAX} file(s) not found, aborting analysis...\n')
       exit()

## calculate number of unique combinations for tqdm print (x = ((n*n)-n)/2)
    uniqueCombinations = int(((len(freqTotalCountDict) * len(freqTotalCountDict)) - len(freqTotalCountDict)) / 2)

## determine parent and daughter sequences
## 1. check accession numbers match
# currently only on top blast hit
    newlyUpdatedCountDict = collections.defaultdict(list)
    combinedDict = collections.defaultdict(list)
    childParentComboDict = {}
    conflictDict = collections.defaultdict(list)
    with tqdm(total = uniqueCombinations, desc = 'Identify artefacts: ', bar_format = '{desc}{percentage:.1f}%|{bar}|{elapsed}<{remaining}') as pbar:
        for parent in range(len(freqTotalCountDict.keys())):
            parentName = list(freqTotalCountDict.keys())[parent]
            newParentDict = freqInputDict[parentName]
            for child in range(parent + 1, len(freqTotalCountDict.keys())):
                pbar.update(1)
                childName = list(freqTotalCountDict.keys())[child]
                try:
                    # 1. check if BLAST tax ID is the same
                    if taxIdInputDict[parentName] != taxIdInputDict[childName]:
                        continue
                    # 2. check BLAST quality on percent identity and query coverage are lower for child than parent
                    if taxPidentInputDict[childName] > taxPidentInputDict[parentName] and taxQcovInputDict[childName] > taxQcovInputDict[parentName]:
                        continue
                    # 3. check if child only appears in samples where parent is present
                    # remove negative controls from co-occurrence patterns
                    # what about abundance?
                    positiveDetectionB = [k for k, v in freqInputDict[childName].items() if v > 1]
                    positiveDetectionA = [k for k, v in freqInputDict[parentName].items() if v > 0]
                    if not all(item in positiveDetectionA for item in positiveDetectionB):
                        continue
                    # 4. check sequence similarity
                    alignments = pairwise2.align.globalxx(seqInputDict[parentName], seqInputDict[childName])
                    distanceCalculation = sum(1 for a, b in zip(alignments[0][0], alignments[0][1]) if a != b)
                    if 100 - (distanceCalculation/ max(len(seqInputDict[parentName]), len(seqInputDict[childName])) * 100) < 85:
                        continue
                    if childName not in childParentComboDict and parentName not in childParentComboDict:
                        childParentComboDict[childName] = parentName
                        combinedDict[parentName].append(childName)
                        # now you can add child numbers to parent
                        for item in newParentDict:
                            newValue = int(newParentDict[item]) + int(freqInputDict[childName][item])
                            newParentDict[item] = newValue
                    elif childName in childParentComboDict and parentName not in childParentComboDict:
                        #print(f'{childName} already identified as child of {childParentComboDict[childName]}, but now also as child of {parentName}, while {parentName} is not identified as child of {childParentComboDict[childName]}')
                        # childName should've already been added to childParentComboDict[childName] at this stage.
                        # so nothing should happen, except keep a log of conflicts for future?
                        conflictDict[childName].append(childParentComboDict[childName])
                        conflictDict[childName].append(parentName)
                    elif childName not in childParentComboDict and parentName in childParentComboDict:
                        #print(f'{childName} identified as child of {parentName}, which in turn is a child of {childParentComboDict[parentName]}, though {childName} not identified as child of {childParentComboDict[parentName]}')
                        # here we should add childName to childParentComboDict[parentName], dependent on what is chosen to do with grandchildren
                        combinedDict[childParentComboDict[parentName]].append(childName)
                        childParentComboDict[childName] = childParentComboDict[parentName]
                        # now you can add child numbers to grandparent
                        for item in newlyUpdatedCountDict[childParentComboDict[parentName]]:
                            newValueGrandParent = int(newlyUpdatedCountDict[childParentComboDict[parentName]][item]) + int(freqInputDict[childName][item])
                            newlyUpdatedCountDict[childParentComboDict[parentName]][item] = newValueGrandParent
                    elif childName in childParentComboDict and parentName in childParentComboDict:
                        if childParentComboDict[childName] != childParentComboDict[parentName]:
                            print(f'both {childName} and {parentName} identified as children of different parents, i.e., {childParentComboDict[childName]} and {childParentComboDict[parentName]}, respectively')
                            # nothing should happen here, as childName is already added to childParentComboDict[childName], though not sure how this combo can happen, needs investigating
                except KeyError:
                    continue
            # if parentName not in childParentComboDict, add parent info to new Dict
            if parentName not in childParentComboDict:
                newlyUpdatedCountDict[parentName] = newParentDict

## write to output
    count = 0
    with open(OUTPUT, 'w') as outfile:
        for item in newlyUpdatedCountDict:
            count += 1
            if count == 1:
                title = "\t".join(newlyUpdatedCountDict[item].keys())
                outfile.write(f'ID\t{title}\n')
            test = "\t".join(str(value) for value in newlyUpdatedCountDict[item].values())
            outfile.write(f'{item}\t{test}\n')

## write log
    print(f'\nSUMMARY STATISTICS:\nNumber of sequences analysed: {len(seqInputDict)}\nSequences identified as artifacts: {len(childParentComboDict)} ({float("{:.2f}".format(len(childParentComboDict) / len(seqInputDict) * 100))}%)\n\nDETAILED LOG:')
    for item in combinedDict:
        print(f'{item} identified as parent sequence of: {" + ".join(combinedDict[item])}')
    print()


    # for item in combinedDict:
    #     print(item, combinedDict[item])
            #print(parentName)
#         for a, b in itertools.combinations(freqTotalCountDict.keys(), 2):
#             pbar.update(1)
#             try:
#                 if taxIdInputDict[a] != taxIdInputDict[b]:
#                     continue
# ## 2. check BLAST quality on percent identity and query coverage
# # currently only on top blast hit
#                 if taxPidentInputDict[b] > taxPidentInputDict[a] and taxQcovInputDict[b] > taxQcovInputDict[a]:
#                     continue
# ## 3. check if b only appears in samples where a is present
#                 positiveDetectionB = [k for k, v in freqInputDict[b].items() if v > 1]
#                 positiveDetectionA = [k for k, v in freqInputDict[a].items() if v > 0]
#                 # remove negative controls from co-occurrence patterns
#                 if not all(item in positiveDetectionA for item in positiveDetectionB):
#                     continue
# ## 4. check sequence similarity
#                 alignments = pairwise2.align.globalxx(seqInputDict[a], seqInputDict[b])
#                 distanceCalculation = sum(1 for a, b in zip(alignments[0][0], alignments[0][1]) if a != b)
#                 if 100 - (distanceCalculation/ max(len(seqInputDict[a]), len(seqInputDict[b])) * 100) < 85:
#                     continue
#                 toCombineDict[a].append(b)
#             except KeyError:
#                 # run taxon-independent approach for NA in BLAST
#                 continue

#     for item in toCombineDict:
#         print(item, toCombineDict[item])


# ## merge values of parents and daughters
# ## remove daughters    
#     newDict = collections.defaultdict(dict)
#     skipDict = {}
#     for item in freqTotalCountDict:
#         if item in skipDict:
#             continue
#         if item not in toCombineDict:
#             newDict[item] = freqInputDict[item]
#         else:
#             dictList = toCombineDict[item]
#             for x in dictList:
#                 skipDict[x] = 1
#             dictList.append(item)
#             newDict[item] = dictionarySum(dictList, freqInputDict)

# ## write to output
#     count = 0
#     with open(OUTPUT, 'w') as outfile:
#         for item in newDict:
#             count += 1
#             if count == 1:
#                 title = "\t".join(newDict[item].keys())
#                 outfile.write(f'ID\t{title}\n')
#             test = "\t".join(str(value) for value in newDict[item].values())
#             outfile.write(f'{item}\t{test}\n')
    
#     for item in toCombineDict:
#         print(item, toCombineDict[item])

############
# ARGPARSE #
############
def main():
    parser = argparse.ArgumentParser(description = 'identify and remove artefact sequences from metabarcoding data')
    parser.add_argument('--version', action = 'version', version = __version__)
    subparser = parser.add_subparsers()

    mrcaCalculatorParser = subparser.add_parser('mrcaCalculator', description = 'calculate the most recent common ancestor from BLAST')
    mrcaCalculatorParser.set_defaults(func = mrcaCalculator)
    
    mrcaMergerParser = subparser.add_parser('mrcaMerger', description = 'merge sequences based on the most recent common ancestor ID')
    mrcaMergerParser.set_defaults(func = mrcaMerger)

    occurMergerParser = subparser.add_parser('occurMerger', description = 'merge sequences based on co-occurrence patterns')
    occurMergerParser.set_defaults(func = occurMerger)

    tombRaiderParser = subparser.add_parser('tombRaider', description = 'merge sequences based on taxon-dependent co-occurrence patterns')
    tombRaiderParser.set_defaults(func = tombRaider)
    tombRaiderParser.add_argument('-f', '--freq', help = 'frequency table input file name', dest = 'freq', type = str)
    tombRaiderParser.add_argument('-z', '--zotu', help = 'zotu sequence input file name', dest = 'zotu', type = str)
    tombRaiderParser.add_argument('-t', '--tax', help = 'taxonomy input file name', dest = 'tax', type = str)
    tombRaiderParser.add_argument('-o', '--output', help = 'frequency table output file name', dest = 'output', type = str)

    args = parser.parse_args()
    args.func(args)

if __name__ == '__main__':
    main()
